{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a50fe399",
   "metadata": {},
   "source": [
    "# Índice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c56344",
   "metadata": {},
   "source": [
    "[Enunciado](#Enunciado)\n",
    "\n",
    "[Filtros disponibles](#Filtros-disponibles)\n",
    "\n",
    "[Organización del código](#Organización-del-código)\n",
    "\n",
    "[Ejecución del código: Ejemplo de funcionamiento](#Ejecución-del-código:-Ejemplo-de-funcionamiento)\n",
    "\n",
    "[Tardanza del código](#Tardanza-del-código)\n",
    "- [Observaciones globales](#Observaciones-globales)\n",
    "\n",
    "[Bibliografía usada](#Bibliografía-usada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa5c5f6",
   "metadata": {},
   "source": [
    "# FILTROS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16da472e",
   "metadata": {},
   "source": [
    "## Enunciado\n",
    "\n",
    "Muestra en vivo el efecto de diferentes filtros, seleccionando con el teclado el filtro deseado y modificando sus parámetros (p.ej. el nivel de suavizado) con trackbars. Aplica el filtro en un ROI para comparar el resultado con el resto de la imagen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4267c912",
   "metadata": {},
   "source": [
    "## Filtros disponibles\n",
    "\n",
    "- **Blanco y negro**\n",
    "\n",
    "  En primer lugar, con el uso de la librería OpenCV se pasa a gris el color de la región de interés. Esto deja la imagen con 1 canal.\n",
    "\n",
    "  En segundo lugar, se vuelve a pasar a BGR porque este es el formato de la imagen completa. Al sobrescribir la región de interés (seleccionada) con el filtro correspondiente, lo que se escribe debe tener el mismo formato que el resto de la imagen (del fotograma).\n",
    "\n",
    "- **Filtro box**\n",
    "\n",
    "  Se utiliza una función de OpenCV que lo realiza. Esta función utiliza un kernel de todos unos para que cada píxel se transforme en una media entre sus vecinos, consiguiendo así un efecto de emborronamiento.\n",
    "\n",
    "- **Filtro gaussiano**\n",
    "\n",
    "  Se utiliza una función de OpenCV que lo realiza.\n",
    "\n",
    "  Una función gaussiana tiene una forma tal que los valores centrales tienen un mayor valor en la componente y que los lejanos al centro. El filtro gaussiano hace algo parecido, de forma que tiene valores mayores en el centro de la matriz utilizada, y valores cada vez más pequeños conforme se aleja del centro de la matriz.\n",
    "\n",
    "  Se puede indicar el tamaño de la desviación estándar en x. Si esta es muy pequeña, el filtro no tendrá mucho efecto. Si es muy grande, la imagen se verá muy emborronada.\n",
    "\n",
    "  Esto es beneficioso para suavizar imágenes y reducir el ruido sin perder demasiada información de detalle. Al contrario que ocurría con el filtro box, que podía añadir ruido a la imagen, el filtro gaussiano no añade ruido.\n",
    "\n",
    "- **Filtro de mediana**\n",
    "\n",
    "  Se utiliza una función de OpenCV.\n",
    "\n",
    "  Este filtro hace que cada pixel se transforme en la mediana de sus vecinos y él mismo.\n",
    "\n",
    "  También se utiliza para reducir el ruido, eliminando los puntos aislados de alta o baja intensidad.\n",
    "\n",
    "- **Filtro bilateral**\n",
    "\n",
    "  Se utiliza una función de OpenCV que lo realiza.\n",
    "\n",
    "  Tal y como indica la [documentación de OpenCV](https://docs.opencv.org/4.x/d4/d86/group__imgproc__filter.html#ga564869aa33e58769b4469101aac458f9), este filtro es muy util para reducir el ruido mientras se mantiene la nitidez de los bordes. El inconveniente es que es más lento que la mayoría de los otros filtros.\n",
    "\n",
    "  Este filtro utiliza dos filtros gaussianos, uno hace que los píxeles cercanos tengan más peso que los lejanos, y el otro hace que los píxeles con valores de intensidad similares tengan más peso. \n",
    "\n",
    "  De esta forma, se consigue que sólo se escojan para el suavizado los píxeles cercanos y con valores similares, lo que hace que los bordes se mantengan nítidos.\n",
    "\n",
    "- **Filtro del mínimo**\n",
    "\n",
    "  Se utiliza una función de la librería SciPy.\n",
    "\n",
    "  Este filtro hace que cada pixel se transforme en el valor mínimo de sus vecinos y él mismo. La cantidad de vecinos viene determinada por un parámetro pasado como argumento a la función.\n",
    "\n",
    "\n",
    "- **Filtro del máximo**\n",
    "\n",
    "  Se utiliza una función de la librería SciPy.\n",
    "\n",
    "  Este filtro hace lo contrario que el anterior, ya que en lugar de tomar el valor mínimo de sus vecinos, toma el valor máximo.\n",
    "\n",
    "  La cantidad de vecinos también viene determinada por un parámetro pasado como argumento a la función.\n",
    "\n",
    "- **Transformación de valor**\n",
    "\n",
    "  Los píxeles de las imágenes pueden ser modificados individualmente sin tener en cuenta su entorno. En este caso, la modificación implica el aumento constante de la luminancia de los píxeles, lo que resulta en un aclarado u oscurecimiento de la imagen.\n",
    "\n",
    "- **Ecualizador del histograma**\n",
    "\n",
    "  Se utiliza una función de OpenCV que lo realiza.\n",
    "\n",
    "  El histograma de una imagen es una representación gráfica de los valores de los píxeles de esta. En este caso, se ha querido ecualizar los valores de luminancia de la imagen, transformando la distribución de los valores para abarcar todo el rango de valores posibles\n",
    "\n",
    "  De esta forma, se se aumenta el contraste de la imagen y haciendo que los detalles sean más visibles. Estos detalles antes podían haber estado ocultos por sobreexposición o subexposición.\n",
    "\n",
    "  Si se quiere leer más información al respecto, se puede consultar la [documentación de OpenCV](https://docs.opencv.org/3.4/d4/d1b/tutorial_histogram_equalization.html).\n",
    "\n",
    "- **CLAHE**\n",
    "\n",
    "  Se utiliza una función de OpenCV que implementa CLAHE.\n",
    "\n",
    "  El ecualizador de histogramas global (el anterior) no consigue mejorar en gran medida las zonas de las imágenes muy claras u oscuras en relación con el resto de la imagen. Esto es debido a que el ecualizador de histogramas no tiene en cuenta la distribución de los valores de los píxeles en zonas concretas de la imagen, sino la distribución global.\n",
    "\n",
    "  Por otro lado, CLAHE utiliza varios histogramas locales, en lugar de uno global, para ecualizar la imagen. Esto permite mejorar las zonas de la imagen que antes no se podían mejorar con el ecualizador de histogramas global.\n",
    "\n",
    "  También es importante destacar que CLAHE limita el contraste de las regiones antes de realizar la ecualización, evitando así la amplificación del ruido en áreas con valores constantes.\n",
    "\n",
    "- **Opening**\n",
    "\n",
    "  Se utiliza una función de OpenCV. Si se quiere saber más, se puede consultar la [siguiente url](https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html#gsc.tab=0).\n",
    "\n",
    "  El opening es una operación morfológica que consiste en aplicar una erosión seguida de una dilatación. Esto es útil para eliminar el ruido de las imágenes.\n",
    "\n",
    "  La erosión en imágenes con solo valores 1 o 0, hace que los píxeles sólo tengan 1 si los píxeles de su alrededor sólo tienen valor 1 (el resto tienen valor 0). La dilatación en ese contexto realiza lo contrario, solo los píxeles que estén rodeados de píxeles de valor 0 se convierten en 0 (el resto son 1s).\n",
    "\n",
    "  Sin embargo, por la manera en la que se implementa en OpenCV, la erosión pone en cada píxel el valor mínimo de los que está rodeado, y la dilatación pone el valor máximo de los que está rodeado.\n",
    "\n",
    "  De esta forma, al aplicar opening a la componente de luminancia de una imagen, se consigue que los píxeles que estén rodeados de píxeles con valores de luminancia muy bajos se conviertan en píxeles con valores de luminancia muy bajos, y los píxeles que estén rodeados de píxeles con valores de luminancia muy altos se conviertan en píxeles con valores de luminancia muy altos, eliminando así los brillos blancos pequeños que puedan formarse en la imagen por la luz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0180faf1",
   "metadata": {},
   "source": [
    "## Organización del código\n",
    "\n",
    "- **filtroConstructor.py**\n",
    "\n",
    "  Este archivo contiene la clase ``Filtro``. Esta clase contiene:\n",
    "  - Un identificador (la tecla asociada para activarlo)\n",
    "  - Un nombre\n",
    "  - Un método para aplicar el filtro a una imagen\n",
    "  - Un método para agregar los trackbars necesarios a la ventana\n",
    "\n",
    "  De esta forma, se conoce la estructura de cada filtro. \n",
    "\n",
    "  El método para aplicar el filtro está implementado, de forma que si una subclase no lo sobrescribe, no se aplica ningún filtro y la imagen se devuelve tal cual. El método para añadir los trackbars también está implementado, de forma que si una subclase no lo sobrescribe, no se añade ningún trackbar.\n",
    "\n",
    "- **filtrosColeccion.py**\n",
    "\n",
    "  Este archivo contiene los filtros que se han añadido al programa. Cada filtro es una subclase de ``Filtro``.\n",
    "\n",
    "  De esta forma, no se necesita modificar el código principal para añadir un nuevo filtro, solo se necesita añadir una nueva subclase de ``Filtro`` en este archivo.\n",
    "\n",
    "- **filtros.py**\n",
    "\n",
    "  Este archivo contiene el código principal del programa.\n",
    "\n",
    "  En primer lugar, se crea la ayuda, que muestra las teclas que se pueden pulsar para activar los filtros, para cambiar la región de interés, para cambiar el modo de visualización, y para mostrar u ocultar la ayuda.\n",
    "\n",
    "  Las teclas que se pueden pulsar para activar los filtros son las que se han asociado a cada filtro en ``filtrosColeccion.py``. \n",
    "\n",
    "  Por otro lado, se guardan los filtros de ``filtrosColeccion.py`` en una lista.\n",
    "\n",
    "  Posteriormente, se realiza lo siguiente por cada fotograma de la cámara:\n",
    "\n",
    "  1. Se guardan las opciones seleccionadas por el usuario.\n",
    "  2. Si se ha presionado una tecla correspondiente a un filtro, y este filtro no es el que ya se está aplicando, se cambia el filtro. Si se cambia de filtro, se vuelve a crear la ventana y se añaden trackbars correpondientes al filtro seleccionado. Esto ocurre porque no se pueden eliminar los trackbars del filtro anterior salvo si se elimina y se vuelve a crear la ventana.\n",
    "  3. Si se ha presionado una tecla para visualizar solo la región de interés o todo el fotograma, o para alternar entre color y blanco y negro, se registra la opción seleccionada.\n",
    "  4. Si se presiona la tecla ``h'', se muestra u oculta la ayuda.\n",
    "  5. Se guarda la región de interés seleccionada.\n",
    "  6. Se aplica el filtro seleccionado a la sección de interés, y se escribe el nombre del filtro.\n",
    "  7. Se pasa a blanco y negro la región de interés si así se ha seleccionado.\n",
    "  8. Se dibuja un rectángulo alrededor de la sección de interés.\n",
    "  9. Se muestra el fotograma o la región de interés (según se haya seleccionado).\n",
    "\n",
    "  De esta forma, el único filtro al que se accede es al filtro NoFiltro, ya que se debe empezar el programa sin ningún filtro aplicado. El resto de filtros pueden añadirse o eliminarse, con el único detalle de que hay que fijarse en no añadir un filtro asociado a una tecla ya usada.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d260a8b",
   "metadata": {},
   "source": [
    "## Ejecución del código: Ejemplo de funcionamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e3f2e3",
   "metadata": {},
   "source": [
    "Para ejecutar el código de FILTROS, se debe de ejecutar el código de `filtros.py` desde la carpeta `FILTROS` en el entorno de anaconda prompt explicado al inicio de la asignatura."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfa04a5",
   "metadata": {},
   "source": [
    "- **Seleccionar ROI**\n",
    "\n",
    "  Se debe de seleccionar una parte de la ventana, de forma que en esta se muestre el filtro seleccionado:\n",
    "\n",
    "  <video src=\"img/seleccionROI.mp4\" controls='play' style=\"width:35%\">\n",
    "  </video>\n",
    "\n",
    "  Como se puede observar, cada vez que se selecciona un filtro, se vuelve a crear la ventana.\n",
    "\n",
    "- **Algunos filtros**\n",
    "\n",
    "  Se muestra el filtro seleccionado en el \"ROI\" cuando se pulsa la tecla correspondiente al filtro, y se pueden modificar algunos parámetros de algunos filtros.\n",
    "\n",
    "  - **Ecualizador de histograma VS CLAHE**\n",
    "  \n",
    "    <video src=\"img/CLAHE-vs-EH.mp4\" controls='play' style=\"width:40%\">\n",
    "    </video>\n",
    "    \n",
    "    Como se puede observar, mientras que CLAHE muestra la imagen con más detalles, el ecualizador de histograma amplifica el ruido de la imagen mostrando zonas demasiado blancas en contraste con otras.\n",
    "\n",
    "  - **Opening**\n",
    "    \n",
    "    <table style=\"width:50%\"><tr>\n",
    "    <td> <img src=\"img/sin-filtro.png\"/> </td>\n",
    "    <td> <img src=\"img/openin.png\"/> </td>\n",
    "    </tr></table>\n",
    "\n",
    "    Como se puede observar, el filtro *opening* permite eliminar los brillos muy blancos que aparecen por las luces (se puede observar en los brillos de las gafas).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4587d5bf",
   "metadata": {},
   "source": [
    "## Tardanza del código"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e16a34",
   "metadata": {},
   "source": [
    "Para ver cuanto tarda en ejecutar el código se va a añadir las siguientes líneas de código al inicio del programa (antes de mostrar frames), y cuando se captura y cuando se muestra el frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306b30d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# ...\n",
    "inicio = time.time()\n",
    "\n",
    "# Código que se hace cada frame\n",
    "\n",
    "fin = time.time()\n",
    "print(fin-inicio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9427f75d",
   "metadata": {},
   "source": [
    "Como se puede observar, este código tarda 0 segundos porque no hace nada en medio, pero al añadirlo a `filtros.py`, el tiempo aumenta:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a56287",
   "metadata": {},
   "source": [
    "- La carga del programa tarda 0.17 segundos en ejecutarse (en efecto, sólo crea la ventana y muestra la ayuda)\n",
    "\n",
    "- **No filtro**: 0.001 segundos\n",
    "\n",
    "- **Box**: Dependiendo del tamaño del ROI, entre *0.001* (pequeño) y *0.003* (grande) segundos.\n",
    "\n",
    "- **Gaussian**: Al igual que en Box, el tamaño del ROI afecta a los segundos. A su vez, cuanto más aumenta el parámetro de desviación estándar, más tarda en ejecutarse (hasta llegar a los *0.26* segundos, cuando al poner poca desviación estándar se obtenían *0.03* segundos). Esto podría deverse a múltiples factores, pero al tener un tamaño de kernel calculado de forma automática, el hacerse con mayor desviación estándar podría indicar que se realiza el filtro con un tamaño de kernel mayor, lo que afectaría al tiempo al tener que consultar más vecinos por cada pixel.\n",
    "\n",
    "- **Median**: Se calcula la mediana, que es una operación rápida, por lo que el tiempo dedicado es pequeño. Al igual que en los anteriores cuanto más grande el tamaño del kernel más tarda en ejecutarse (de *0.01* a *0.05* segundos).\n",
    "\n",
    "- **Bilateral**: Es el que más tarda en ejecutarse. Tarda *2.2* segundos en los valores por defecto (15 y 15), pero si estos se disminuyen el tiempo así lo hace (con 7 tardan *0.5* segundos y con 1 tardan *0.01* segundos). El disminuir Sigma Color (a 3) manteniendo el Sigma Space(a 15) no baja en excesivo el tiempo (*2.08* segundos), pero al contrario baja a *0.07* segundos. \n",
    "\n",
    "  Esto tiene su explicación en que, como se explicó en la memoria, Sigma Space indica qué píxeles se consideran lo suficientemente cercanos para tenerse en cuenta (de forma que cuanto más cercano más peso tiene), por lo que su disminución implica tener en cuenta menos píxeles. Sin embargo, Sigma Color indica los colores, por lo que se tendrán que seguir revisando todos los píxeles para ver su color.\n",
    "\n",
    "- **Minimo** y **Máximo**: Desde *0.03* segundos con tamaño de kernel pequeño hasta *0.1* segundos con tamaño de kernel grande. \n",
    "\n",
    "  Al igual que los anteriores, el tener un tamaño de ROI pequeño hace que el tiempo disminuya (*0.1* tamaño de kernel y ROI grande, *0.004* tamaño de ROI pequeño y de kernel grande).\n",
    "\n",
    "- **Transformación de valor**: Al sumar un valor constante a cada pixel, el valor no influye en el tiempo. El tamaño del ROI influye, pero menos que otros debido a que no se deben realizar muchas operaciones para calcular una suma. Por ello, la diferencia va de *0.001* segundos hasta *0.004* segundos\n",
    "\n",
    "- **Ecualizador de histograma**: Dependiendo del tamaño del ROI, entre *0.001* y *0.004* segundos.\n",
    "\n",
    "- **CLAHE**: Es más pesado que el ecualizador de histogramas, ya que realiza histogramas locales en vez de uno global, por lo que tarda más (entre *0.001* y *0.01* segundos).\n",
    "\n",
    "- **Opening**: Dependiendo del tamaño del ROI, entre *0.001* y *0.003* segundos. No se realiza muchos cálculos, por lo que tiene sentido su tardanza."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2d4547",
   "metadata": {},
   "source": [
    "### Observaciones globales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd742a9",
   "metadata": {},
   "source": [
    "- Cuanto más grande es el kernel, más tarda el filtro en ejecutarse\n",
    "- Cuanto más grande es el ROI, más tarda el filtro en ejecutarse\n",
    "- Cuando más acciones debe realizar el filtro, más diferencia hay entre los casos rápidos (tamaño de ROI o/y kernel pequeño) y los casos lentos (tamaño del ROI o/y kernel grande)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad208c2",
   "metadata": {},
   "source": [
    "## Bibliografía usada\n",
    "\n",
    "[Filtros usados de OpenCV](https://docs.opencv.org/4.x/d4/d13/tutorial_py_filtering.html)\n",
    "\n",
    "[Más documentación de OpenCV](https://docs.opencv.org/4.x/d4/d86/group__imgproc__filter.html#ga564869aa33e58769b4469101aac458f9)\n",
    "\n",
    "[Ecualizador de histogramas de OpenCV](https://docs.opencv.org/3.4/d4/d1b/tutorial_histogram_equalization.html)\n",
    "\n",
    "[Preguntas a ChatGPT para aclarar conceptos](https://chat.openai.com)\n",
    "\n",
    "[CLAHE](https://en.wikipedia.org/wiki/Adaptive_histogram_equalization)\n",
    "\n",
    "[Función morphologyEx()](https://docs.opencv.org/4.x/d4/d86/group__imgproc__filter.html#ga67493776e3ad1a3df63883829375201f)\n",
    "\n",
    "[Función erode()](https://docs.opencv.org/4.x/d4/d86/group__imgproc__filter.html#gaeb1e0c1033e3f6b891a25d0511362aeb)\n",
    "\n",
    "[Función dilate()](https://docs.opencv.org/4.x/d4/d86/group__imgproc__filter.html#ga4ff0f3318642c4f469d0e11f242f3b6c)\n",
    "\n",
    "[Como añadir trackbars a una ventana con OpenCV](https://docs.opencv.org/3.4/da/d6a/tutorial_trackbar.html)\n",
    "\n",
    "[Acceder a las subclases de una clase en Python](https://stackoverflow.com/questions/3862310/how-to-find-all-the-subclasses-of-a-class-given-its-name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
